{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff26aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3dfa33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INDEX_FILE = \"vector_store.index\"\n",
    "META_FILE = \"metadata.json\"\n",
    "EMBED_MODEL=\"nomic-embed-text:latest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1e6697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted text length: 4341\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load HTML File\n",
    "html_file_path = \"./generated_kba/OPS-1024_Troubleshooting_Article.html\"\n",
    "article_name = \"OPS-1024_Troubleshooting_Article\"\n",
    "\n",
    "with open(html_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "# Extract Clean Text from HTML\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Remove scripts/styles\n",
    "for tag in soup([\"script\", \"style\"]):\n",
    "    tag.decompose()\n",
    "\n",
    "clean_text = soup.get_text(separator=\" \", strip=True)\n",
    "\n",
    "print(\"Extracted text length:\", len(clean_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3cd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Embedding\n",
    "\n",
    "def chunk_text(text, chunk_size=500, overlap=50):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunks.append(text[i:i+chunk_size])\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(clean_text)\n",
    "\n",
    "embedding_response = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    response = ollama.embeddings(\n",
    "        model=EMBED_MODEL,\n",
    "        prompt=chunk\n",
    "    )\n",
    "    embedding_response.append(response[\"embedding\"])\n",
    "\n",
    "\n",
    "embedding = np.array(embedding_response).astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b88c365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML article embedded and stored successfully.\n",
      "Total vectors in index: 170\n",
      "Total metadata records: 170\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Validate embedding shape\n",
    "if len(embedding.shape) == 1:\n",
    "    embedding = np.expand_dims(embedding, axis=0)\n",
    "\n",
    "# Normalize for cosine similarity\n",
    "\n",
    "faiss.normalize_L2(embedding)\n",
    "\n",
    "dimension = embedding.shape[1]\n",
    "\n",
    "# Create / Load FAISS Index\n",
    "\n",
    "if os.path.exists(INDEX_FILE):\n",
    "    index = faiss.read_index(INDEX_FILE)\n",
    "\n",
    "    # Safety check for dimension mismatch\n",
    "    if index.d != dimension:\n",
    "        raise ValueError(\n",
    "            f\"Embedding dimension mismatch! \"\n",
    "            f\"Index dimension = {index.d}, \"\n",
    "            f\"New embedding dimension = {dimension}\"\n",
    "        )\n",
    "else:\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "\n",
    "# Add embedding\n",
    "index.add(embedding)\n",
    "\n",
    "# Save index\n",
    "faiss.write_index(index, INDEX_FILE)\n",
    "\n",
    "# Store Metadata PER CHUNK\n",
    "\n",
    "if os.path.exists(META_FILE):\n",
    "    with open(META_FILE, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "else:\n",
    "    metadata = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    metadata.append({\n",
    "        \"article_name\": article_name,\n",
    "        \"source_file\": html_file_path,\n",
    "        \"chunk_id\": i,\n",
    "        \"chunk_text\": chunk\n",
    "    })\n",
    "\n",
    "with open(META_FILE, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"HTML article embedded and stored successfully.\")\n",
    "print(\"Total vectors in index:\", index.ntotal)\n",
    "print(\"Total metadata records:\", len(metadata))\n",
    "\n",
    "# CRITICAL CHECK\n",
    "assert index.ntotal == len(metadata), \"Index and metadata count mismatch!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee7c6f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Similar KBA Found:\n",
      "Article Name: OPS-1024_Troubleshooting_Article\n",
      "Source File: generated_kba/OPS-1024_Troubleshooting_Article.html\n",
      "Cosine Similarity Score: 82.39 %\n",
      "Total vectors in index: 170\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load FAISS index FIRST\n",
    "index = faiss.read_index(INDEX_FILE)\n",
    "\n",
    "if index.ntotal == 0:\n",
    "    raise ValueError(\"FAISS index is empty!\")\n",
    "\n",
    "dimension = index.d  # get dimension directly from index\n",
    "\n",
    "# Create embedding\n",
    "new_ticket = \"Service disruption triggered by full root filesystem it went down entirely due to insufficient disk space on its root filesystem. This resulted in slow SSH connections\"\n",
    "\n",
    "embedding_response = ollama.embeddings(\n",
    "    model=EMBED_MODEL,\n",
    "    prompt=new_ticket\n",
    ")\n",
    "\n",
    "query_vector = np.array(\n",
    "    [embedding_response[\"embedding\"]],\n",
    "    dtype=\"float32\"\n",
    ")\n",
    "# print(\"Query embedding shape:\", query_vector)\n",
    "\n",
    "# Validate dimension\n",
    "if query_vector.shape[1] != dimension:\n",
    "    raise ValueError(\n",
    "        f\"Dimension mismatch! Query dim={query_vector.shape[1]}, Index dim={dimension}\"\n",
    "    )\n",
    "\n",
    "# Normalize query (REQUIRED for cosine similarity)\n",
    "faiss.normalize_L2(query_vector)\n",
    "\n",
    "# Search\n",
    "distances, indices = index.search(query_vector, k=1)\n",
    "\n",
    "score = float(distances[0][0])\n",
    "match_index = int(indices[0][0])\n",
    "\n",
    "# Load metadata\n",
    "with open(META_FILE, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "if match_index >= len(metadata):\n",
    "    raise ValueError(\"Metadata mismatch with FAISS index!\")\n",
    "\n",
    "matched_article = metadata[match_index]\n",
    "print(\"\\nMost Similar KBA Found:\")\n",
    "print(\"Article Name:\", matched_article[\"article_name\"])\n",
    "print(\"Source File:\", matched_article[\"source_file\"])\n",
    "print(\"Cosine Similarity Score:\", round(score, 4)*100, \"%\")\n",
    "print(\"Total vectors in index:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6770d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

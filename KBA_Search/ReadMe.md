# ğŸ“˜ KBA Semantic Search System (Chunk-Based + Cosine Similarity)

An AI-powered Knowledge Base Article (KBA) search engine that uses **embeddings + FAISS vector database + cosine similarity** to retrieve the most relevant troubleshooting articles based on a new ticket description.

This project processes HTML-based KBA articles, converts them into embeddings, stores them in a vector database, and retrieves the best matching article using **chunk-level aggregation**.

---

## ğŸš€ Features

- âœ… Load multiple HTML KBA files from a folder  
- âœ… Extract clean text from HTML  
- âœ… Chunk large articles for better semantic accuracy  
- âœ… Generate embeddings using Ollama  
- âœ… Store vectors in FAISS  
- âœ… Use cosine similarity (`IndexFlatIP + L2 normalization`)  
- âœ… Retrieve top matching chunks  
- âœ… Aggregate chunk scores per article  
- âœ… Rank articles by combined similarity score  

---

## ğŸ— Architecture
HTML KBA Files
â†“
Text Extraction (BeautifulSoup)
â†“
Chunking
â†“
Embedding Generation (Ollama)
â†“
Vector Storage (FAISS)
â†“
Query Embedding
â†“
Top-K Chunk Search
â†“
Article Score Aggregation
â†“
Best Matching KBA


---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone <your-repo-url>
cd kba-search
```
2ï¸âƒ£ Install Dependencies
pip install faiss-cpu numpy beautifulsoup4 ollama
3ï¸âƒ£ Install & Pull Embedding Model (Ollama)

Make sure Ollama is installed:
ollama pull nomic-embed-text

ğŸ§  How It Works
1ï¸âƒ£ Index KBA Articles
Reads all .html files from kba_articles/
Extracts clean text
Splits text into chunks
Creates embeddings
Normalizes vectors
Stores vectors in FAISS
Saves metadata mapping

2ï¸âƒ£ Search for Similar KBA
Provide a new ticket description:
search_similar_kba("Root filesystem full causing SSH failure")

The system will:
Generate embedding for the ticket
Normalize vector
Search top 5 chunks
Group chunks by article
Sum similarity scores
Rank articles
Return best match

ğŸ” Cosine Similarity Implementation
faiss.IndexFlatIP(dimension)
faiss.normalize_L2(vector)

Why?
Inner Product (IP) becomes Cosine Similarity when vectors are normalized. This ensures semantic similarity based on vector direction, not magnitude.

ğŸ“Š Example Output
ğŸ” Aggregated Article Ranking:

Article: OPS-1024
Total Combined Score: 1.72

Article: DB-204
Total Combined Score: 0.83

ğŸ† FINAL BEST MATCH
Article: OPS-1024
ğŸ§© Metadata Structure

Each stored chunk has metadata:

[
  {
    "article_name": "OPS-1024",
    "source_file": "OPS-1024.html",
    "chunk_id": 0
  }
]

This ensures proper mapping between:
FAISS Index Position â†’ Chunk â†’ Article

ğŸ§  Tech Stack
-Python
-FAISS
-Ollama (Embeddings)
-BeautifulSoup
-NumPy

ğŸ¯ Use Cases
-IT ticket auto-resolution
-Enterprise knowledge retrieval
-Internal documentation search
-DevOps troubleshooting assistant
-Support automation system

ğŸ›¡ Production Recommendations
-Always normalize vectors before storing & searching
-Keep FAISS and metadata order synchronized
-Chunk large documents (800â€“1000 characters recommended)
-Validate embedding dimensions before search

